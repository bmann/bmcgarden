---
link: https://situational-blindness.ai/
tags:
  - AI
---
A response to [[Leopold Aschenbrenner]]'s [[Situational Awareness]]

[Both a PDF of the full essay and an audio version are available for your convenience.](https://situational-blindness.ai/#section10) If you like my work, please feel free to follow me on [@IridiumEagle](https://x.com/IridiumEagle)

> Leopold Aschenbrenner is a young man. He writes with the barely contained breathless enthusiasm of the true believer who is stretching out his hands to a crowd of onlookers, ready to pull them into giddy flights of intellect that he has trailed in the morning sky. He lets you know, right there, at the beginning, that you are soon to be an initiate to secrets only the elect few have reckoned with. As well put together as his multi-chapter writing is, its most interesting aspect is the insight it seems to lend into his psychology and that of his fellow aspirants. To reframe a line from the essay: if these are the attitudes of the people in charge of developing the world’s most advanced technology, we’re in for a wild ride.

> ...The domain he’s working in is in its infancy. His own experience is limited. He has trendlines but no context or real precedents; the precedent he chooses is flawed. He ignores wide swathes of crucial social, economic and political theory. His geopolitical sections are jingoistic caricatures that nonetheless read as self-assured as his technical sections. Despite writing chapters of text, he rushes to his conclusions.

- In [Part 2](https://situational-blindness.ai/#section2), we’ll examine how Leopold’s projections fail to consider any of the obvious social implications of the the timelines he proposes, which will confound the projections themselves
- In [Part 3](https://situational-blindness.ai/#section3), we’ll look at how he sets up potential obstacles to his proposed timeline as straw men that he can blow over with mere intuition and builds a scary historical analogy based on a misapprehension of the way knowledge diffuses in his own field
- In [Part 4](https://situational-blindness.ai/#section4), we’ll review how his proposal for the government to subsidize the infrastructure of the US’ biggest and most profitable tech companies in the name of democracy would actually lead to a democratic collapse at home and a destabilization of democracies abroad
- In [Part 5](https://situational-blindness.ai/#section5), we’ll review how his proposed military-grade secrecy around both AGI and AI safety would greatly diminish global security in relation to AGI hacking to no purpose (as the US is an irredeemably soft target for nation state hackers), and how his favored foreign policy would unite the world against the US
- In [Part 6](https://situational-blindness.ai/#section6), we’ll use a lens of fragility to show how Leopold’s policy suggestions are more likely than any other policies to cause the very catastrophes he fears
- And in [Part 7](https://situational-blindness.ai/#section7), we’ll propose an alternative to his reductive and antidemocratic approach, that has some chance of being successful